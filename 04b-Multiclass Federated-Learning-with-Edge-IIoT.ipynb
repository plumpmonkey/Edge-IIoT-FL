{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04b - Multiclass Federated Learning with Edge IIoT Dataset using Flower and TensorFlow/Keras\n",
    "\n",
    "In this notebook we use the Flower Federated Learning library (flower.dev) with Tensorflow/Keras to distribute the Edge-IIoT data across multiple clients in various different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATIFIED\n"
     ]
    }
   ],
   "source": [
    "### THIS SECTION NEEDS TO BE SET TO DETERMINE WHICH CONFIGURATION METHOD TO UTILISE\n",
    "\n",
    "SPLIT_AVAILABLE_METHODS = ['INDIVIDUAL_ATTACK', 'ATTACK_GROUP', 'STRATIFIED']\n",
    "METHOD = 'STRATIFIED'\n",
    "NUM_OF_STRATIFIED_CLIENTS = 10 # only applies to stratified method\n",
    "print (METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install flwr[simulation] torch torchvision matplotlib sklearn openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flwr as fl\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from flwr.common import Metrics\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.3.0\n",
      "numpy 1.24.2\n",
      "torch 1.13.1\n",
      "torchvision 0.14.1\n",
      "Training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../datasets/Edge-IIoT/\"\n",
    "\n",
    "df = pd.read_pickle(dataset_path + \"Edge-IIoTset dataset/Selected dataset for ML and DL/ML-EdgeIIoT-dataset.pkl\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataframe for Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass attack dataframe\n",
    "multiclass_df = df[['frame.time', 'ip.src_host', 'ip.dst_host', 'arp.dst.proto_ipv4',\n",
    "       'arp.opcode', 'arp.hw.size', 'arp.src.proto_ipv4', 'icmp.checksum',\n",
    "       'icmp.seq_le', 'icmp.transmit_timestamp', 'icmp.unused',\n",
    "       'http.file_data', 'http.content_length', 'http.request.uri.query',\n",
    "       'http.request.method', 'http.referer', 'http.request.full_uri',\n",
    "       'http.request.version', 'http.response', 'http.tls_port', 'tcp.ack',\n",
    "       'tcp.ack_raw', 'tcp.checksum', 'tcp.connection.fin',\n",
    "       'tcp.connection.rst', 'tcp.connection.syn', 'tcp.connection.synack',\n",
    "       'tcp.dstport', 'tcp.flags', 'tcp.flags.ack', 'tcp.len', 'tcp.options',\n",
    "       'tcp.payload', 'tcp.seq', 'tcp.srcport', 'udp.port', 'udp.stream',\n",
    "       'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu',\n",
    "       'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request',\n",
    "       'dns.retransmit_request_in', 'mqtt.conack.flags',\n",
    "       'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len',\n",
    "       'mqtt.msg_decoded_as', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len',\n",
    "       'mqtt.protoname', 'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver',\n",
    "       'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id',\n",
    "       'Attack_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known_sensor_ip_addresses: ['192.168.0.101', '192.168.2.194', '192.168.3.18', '192.168.4.73', '192.168.5.47', '192.168.6.56', '192.768.7.62', '192.168.8.163']\n",
      "known_attacker_ip_addresses: \n",
      "Number of IPs 22\n",
      "['142.250.200.205', '94.196.109.185', '192.168.0.170', '213.117.18.213', '91.184.12.91', '16.226.184.201', '216.58.198.74', '227.117.33.125', '153.125.214.15', '166.153.227.121', '104.16.87.20', '142.250.201.10', '220.146.94.148', '183.223.100.122', '133.149.252.77', '172.217.19.35', '192.168.0.152', '192.168.0.101', '207.192.25.133', '172.217.19.42', '190.123.219.128', '49.81.59.152']\n"
     ]
    }
   ],
   "source": [
    "known_sensor_ip_addresses = [ '192.168.0.101', '192.168.2.194', '192.168.3.18', '192.168.4.73', '192.168.5.47', '192.168.6.56', '192.768.7.62', '192.168.8.163']\n",
    "print (\"known_sensor_ip_addresses:\", known_sensor_ip_addresses)\n",
    "\n",
    "tcp_dos_attack_ip_addresses = [ '207.192.25.133', '94.196.109.185', '133.149.252.77', '220.146.94.148' ]\n",
    "tdp_dos_atack_ip_addresses = [ '190.123.219.128', '16.226.184.201', '153.125.214.15', '91.184.12.91' ]\n",
    "http_attack_ip_addresses = [ '192.168.0.170', '216.58.198.74' ]\n",
    "icmp_flood_attack_ip_addresses = [ '213.117.18.213', '183.223.100.122', '166.153.227.121', '49.81.59.152', '227.117.33.125' ]\n",
    "port_scan_attack_ip_addresses = [ '192.168.0.170' ]\n",
    "os_fingerprinting_attack_ip_addresses = [ '192.168.0.170' ]\n",
    "vuln_scan_attack_ip_addresses = [ '192.168.0.170', '142.250.200.205', '172.217.19.35', '142.250.201.10' ]\n",
    "dns_spoof_attack_ip_addresses = [ '192.168.0.101', '192.168.0.152', '172.217.19.35', '192.168.0.170' ]\n",
    "arp_spoof_attack_ip_addresses = [ '192.168.0.101', '192.168.0.152', '172.217.19.35', '192.168.0.170' ]\n",
    "xss_attack_ip_addresses = [ '192.168.0.170', '172.217.19.42', '104.16.87.20' ]\n",
    "sql_injection_attack_ip_addresses = [ '192.168.0.170' ]\n",
    "upload_attack_ip_addresses = [ '192.168.0.170' ]\n",
    "backdoor_attack_ip_addresses = [ '192.168.0.170' ]\n",
    "password_attack_ip_addresses = [ '192.168.0.170' ]\n",
    "ransomware_attack_ip_addresses = [ '192.168.0.170' ] \n",
    "\n",
    "# Combine all attack IP addresses into one list, ensuring no duplicates\n",
    "known_attacker_ip_addresses = list(set(tcp_dos_attack_ip_addresses + tdp_dos_atack_ip_addresses + http_attack_ip_addresses + icmp_flood_attack_ip_addresses + port_scan_attack_ip_addresses + os_fingerprinting_attack_ip_addresses + vuln_scan_attack_ip_addresses + dns_spoof_attack_ip_addresses + arp_spoof_attack_ip_addresses + xss_attack_ip_addresses + sql_injection_attack_ip_addresses + upload_attack_ip_addresses + backdoor_attack_ip_addresses + password_attack_ip_addresses + ransomware_attack_ip_addresses))\n",
    "print (f\"known_attacker_ip_addresses: \\nNumber of IPs {len(known_attacker_ip_addresses)}\\n{known_attacker_ip_addresses}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of DDOS attacks, the attacks mainly come from a small subset of IP addresses. `192.168.0.170` being responsible for a lot of the attacks. From the data exploration workbook `02b-ML-Data-Exploration.ipynb` we can also see that the attacked IP is always the `192.168.0.128` edge server. This means it is not feasible the divide the traffic either by attacker or attacked IP address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data encoding (Dummy Encoding):\n",
    "\n",
    "EG. Takes a product category and converts it to a binary vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_dummy(df, name):\n",
    "\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "\n",
    "    for x in dummies.columns:\n",
    "\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "\n",
    "        df[dummy_name] = dummies[x]\n",
    "\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "encode_text_dummy(multiclass_df,'http.request.method')\n",
    "\n",
    "encode_text_dummy(multiclass_df,'http.referer')\n",
    "\n",
    "encode_text_dummy(multiclass_df,\"http.request.version\")\n",
    "\n",
    "encode_text_dummy(multiclass_df,\"dns.qry.name.len\")\n",
    "\n",
    "encode_text_dummy(multiclass_df,\"mqtt.conack.flags\")\n",
    "\n",
    "encode_text_dummy(multiclass_df,\"mqtt.protoname\")\n",
    "\n",
    "encode_text_dummy(multiclass_df,\"mqtt.topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max index value of binary_df: 157799\n",
      "(157800, 90)\n"
     ]
    }
   ],
   "source": [
    "# print max index value of binary_df\n",
    "print(\"max index value of binary_df:\", max(multiclass_df.index))\n",
    "print(multiclass_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop some unrequired columns from the DF, but we need to keep the original around as we may need to split the data differently for different models based on things like the IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip.src_host                            0\n",
       "ip.dst_host                            0\n",
       "arp.opcode                             0\n",
       "arp.hw.size                            0\n",
       "icmp.checksum                          0\n",
       "                                      ..\n",
       "mqtt.protoname-0.0                     0\n",
       "mqtt.protoname-MQTT                    0\n",
       "mqtt.topic-0                           0\n",
       "mqtt.topic-0.0                         0\n",
       "mqtt.topic-Temperature_and_Humidity    0\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop_columns = [\"frame.time\", \"ip.src_host\", \"ip.dst_host\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\", \n",
    "drop_columns = [\"frame.time\", \"arp.src.proto_ipv4\",\"arp.dst.proto_ipv4\", \n",
    "\n",
    "         \"http.file_data\",\"http.request.full_uri\",\"icmp.transmit_timestamp\",\n",
    "\n",
    "         \"http.request.uri.query\", \"tcp.options\",\"tcp.payload\",\"tcp.srcport\",\n",
    "\n",
    "         \"tcp.dstport\", \"udp.port\", \"mqtt.msg\"]\n",
    "\n",
    "multiclass_df = multiclass_df.drop(drop_columns, axis=1)\n",
    "\n",
    "multiclass_df = multiclass_df.dropna(axis=0, how='any')\n",
    "\n",
    "multiclass_df = multiclass_df.drop_duplicates(subset=None, keep=\"first\")\n",
    "\n",
    "# We cant shuffle at this point as we need to keep the order so we can split the dataset later based on things like IP address\n",
    "#binary_df_copy = shuffle(binary_df_copy)\n",
    "\n",
    "# Compute the number of missing values (NaN or null) in each column of a pandas DataFrame object named df.\n",
    "multiclass_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max index value of binary_df: 157799\n",
      "(153225, 77)\n",
      "max index value of binary_df: 153224\n",
      "(153225, 77)\n"
     ]
    }
   ],
   "source": [
    "# print max index value of binary_df\n",
    "print(\"max index value of binary_df:\", max(multiclass_df.index))\n",
    "print(multiclass_df.shape)\n",
    "\n",
    "multiclass_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print max index value of binary_df\n",
    "print(\"max index value of binary_df:\", max(multiclass_df.index))\n",
    "print(multiclass_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the Attack Type to be a unique number for the attack type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of Types\n",
    "attacks = {'Normal': 0 ,'Backdoor' :1, 'DDoS_HTTP':2,  'DDoS_ICMP':3, 'DDoS_TCP':4, 'DDoS_UDP':5, \n",
    "           'Fingerprinting':6, 'MITM':7, 'Password':8, 'Port_Scanning':9, 'Ransomware':10, \n",
    "           'SQL_injection':11, 'Uploading':12, 'Vulnerability_scanner':13, 'XSS':14}\n",
    "\n",
    "multiclass_df['Attack_type'] = multiclass_df['Attack_type'].map(attacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122580, 77)\n",
      "122579\n",
      "153224\n"
     ]
    }
   ],
   "source": [
    "label = multiclass_df['Attack_type']\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_n = le.fit_transform(label.values)\n",
    "\n",
    "# Stratify based on the attack label to balance the dataset - This is our original copy of the data include IP addresses\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(multiclass_df, label_n, stratify=label_n, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train_df.shape)\n",
    "\n",
    "X_train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#print the max index of X_train_df\n",
    "print(X_train_df.index.max())\n",
    "\n",
    "#  print the max index of multiclass_df\n",
    "print(multiclass_df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(label_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (122580, 74) (122580,)\n",
      "Test: (30645, 74) (30645,)\n"
     ]
    }
   ],
   "source": [
    "multiclass_df_copy = multiclass_df.copy()\n",
    "\n",
    "multiclass_df_copy = multiclass_df_copy.drop([\"ip.src_host\", \"ip.dst_host\", \"Attack_type\"], axis=1)\n",
    "\n",
    "# This is our copy of the data without IP addresses\n",
    "scaled_features = StandardScaler().fit_transform(multiclass_df_copy.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, label_n, stratify=label_n, test_size=0.2, random_state=42)\n",
    "\n",
    "print (\"Train:\", X_train.shape, y_train.shape)\n",
    "print (\"Test:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [     0     19     25 ... 122549 122557 122567]\n",
      "TRAIN: [     2     13     21 ... 122544 122568 122573]\n",
      "TRAIN: [     6     12     20 ... 122574 122576 122577]\n",
      "TRAIN: [    35     56     73 ... 122554 122565 122570]\n",
      "TRAIN: [     3      4      5 ... 122536 122572 122579]\n",
      "TRAIN: [     7     11     14 ... 122533 122563 122575]\n",
      "TRAIN: [    10     50     61 ... 122561 122564 122571]\n",
      "TRAIN: [     9     18     24 ... 122550 122555 122560]\n",
      "TRAIN: [     1     15     26 ... 122547 122562 122569]\n",
      "TRAIN: [    17     29     32 ... 122559 122566 122578]\n"
     ]
    }
   ],
   "source": [
    "fl_X_train = []\n",
    "fl_y_train = []\n",
    "\n",
    "if METHOD == 'STRATIFIED':\n",
    "    # Stratfiy the dataset\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=NUM_OF_STRATIFIED_CLIENTS, shuffle=True, random_state=42)\n",
    "    skf.get_n_splits(X_train, y_train)\n",
    "\n",
    "    for _, train_index in skf.split(X_train, y_train):\n",
    "        print(\"TRAIN:\", train_index)\n",
    "        X_np = X_train[train_index]\n",
    "        y_np = y_train[train_index]\n",
    "\n",
    "        fl_X_train.append(X_np)\n",
    "        fl_y_train.append(y_np)\n",
    "\n",
    "else: # UNUSED\n",
    "    # Individual IP address\n",
    "    for ip in known_sensor_ip_addresses:\n",
    "        new_ip = [ip]\n",
    "        print(\"new_ip:\", new_ip)\n",
    "\n",
    "        X_train_df['ip.src_host']\n",
    "        \n",
    "        print(\"Shape X_Train:\", X_train.shape)\n",
    "        print(\"Shape y_Train:\", y_train.shape)\n",
    "\n",
    "        # Filter dataframe by IP address\n",
    "        new_df_src = X_train_df[ X_train_df['ip.src_host'].isin(new_ip) ]\n",
    "        new_df_dst = X_train_df[ X_train_df['ip.dst_host'].isin(new_ip) ]\n",
    "\n",
    "        print(\"Shape new_df_src:\", new_df_src.shape)\n",
    "        print(\"Shape new_df_dst:\", new_df_dst.shape)\n",
    "\n",
    "        X_np = np.vstack([ X_train[ new_df_src.index, : ], X_train[ new_df_dst.index, :] ])\n",
    "        y_np = np.hstack([ y_train[ new_df_src.index ], y_train[ new_df_dst.index ] ])\n",
    "\n",
    "        print (\"x_np:\", X_np.shape)\n",
    "        print (\"y_np:\", y_np.shape)\n",
    "\n",
    "        fl_X_train.append(X_np)\n",
    "        fl_y_train.append(y_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_X_train size: 10\n",
      "fl_X_train[ 0 ]: (12258, 74)\n",
      "fl_y_train[ 0 ]: (12258,)\n",
      "fl_X_train[ 1 ]: (12258, 74)\n",
      "fl_y_train[ 1 ]: (12258,)\n",
      "fl_X_train[ 2 ]: (12258, 74)\n",
      "fl_y_train[ 2 ]: (12258,)\n",
      "fl_X_train[ 3 ]: (12258, 74)\n",
      "fl_y_train[ 3 ]: (12258,)\n",
      "fl_X_train[ 4 ]: (12258, 74)\n",
      "fl_y_train[ 4 ]: (12258,)\n",
      "fl_X_train[ 5 ]: (12258, 74)\n",
      "fl_y_train[ 5 ]: (12258,)\n",
      "fl_X_train[ 6 ]: (12258, 74)\n",
      "fl_y_train[ 6 ]: (12258,)\n",
      "fl_X_train[ 7 ]: (12258, 74)\n",
      "fl_y_train[ 7 ]: (12258,)\n",
      "fl_X_train[ 8 ]: (12258, 74)\n",
      "fl_y_train[ 8 ]: (12258,)\n",
      "fl_X_train[ 9 ]: (12258, 74)\n",
      "fl_y_train[ 9 ]: (12258,)\n"
     ]
    }
   ],
   "source": [
    "# Print out the size of the fl_X_train\n",
    "print (\"fl_X_train size:\", len(fl_X_train))\n",
    "\n",
    "# Print out the size of each element in the fl_X_train\n",
    "for i in range(len(fl_X_train)):\n",
    "    print (\"fl_X_train[\", i, \"]:\", fl_X_train[i].shape)\n",
    "    print (\"fl_y_train[\", i, \"]:\", fl_y_train[i].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label.unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_OF_CLIENTS: 10\n",
      "Checking data split groups\n",
      "0 : X Shape (12258, 74) Y Shape (12258,)\n",
      "1 : X Shape (12258, 74) Y Shape (12258,)\n",
      "2 : X Shape (12258, 74) Y Shape (12258,)\n",
      "3 : X Shape (12258, 74) Y Shape (12258,)\n",
      "4 : X Shape (12258, 74) Y Shape (12258,)\n",
      "5 : X Shape (12258, 74) Y Shape (12258,)\n",
      "6 : X Shape (12258, 74) Y Shape (12258,)\n",
      "7 : X Shape (12258, 74) Y Shape (12258,)\n",
      "8 : X Shape (12258, 74) Y Shape (12258,)\n",
      "9 : X Shape (12258, 74) Y Shape (12258,)\n",
      "\n",
      "Deploy Simulation\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_CLIENTS = len(fl_X_train)\n",
    "print(\"NUM_OF_CLIENTS:\", NUM_OF_CLIENTS)    \n",
    "\n",
    "NUM_OF_ROUNDS = 15\n",
    "\n",
    "print(\"Checking data split groups\")\n",
    "for i in range(len(fl_X_train)):\n",
    "    print(i, \":\", \"X Shape\", fl_X_train[i].shape, \"Y Shape\", fl_y_train[i].shape)\n",
    "\n",
    "print(\"\\nDeploy Simulation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FL Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE TO SELF - BUILD IN F1 SCORE  - https://www.kaggle.com/code/gpiosenka/flower-classification-f1-score-93\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-06 14:06:24,844 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=15, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn 1.2.0.\n",
      "flwr 1.3.0\n",
      "numpy 1.24.2\n",
      "tf 2.11.0\n",
      "Deploy simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 14:06:32,309\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-07-06 14:06:35,594 | app.py:179 | Flower VCE: Ray initialized with resources: {'CPU': 24.0, 'GPU': 1.0, 'object_store_memory': 3460152115.0, 'node:127.0.0.1': 1.0, 'memory': 6920304231.0}\n",
      "INFO flwr 2023-07-06 14:06:35,595 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-07-06 14:06:35,595 | server.py:270 | Requesting initial parameters from one random client\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=49848)\u001b[0m Client ID: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-06 14:06:41,480 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flwr 2023-07-06 14:06:41,481 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"sequential_7\" with a weight list of length 262, but the layer was expecting 6 weights. Provided weights: [array([[[[-0.08516684, -0.04290653, -0.05079073, ...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jon\\Documents\\VSCode Projects\\Edge-IIoT-FL\\04b-Multiclass Federated-Learning-with-Edge-IIoT.ipynb Cell 29\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m strategy \u001b[39m=\u001b[39m fl\u001b[39m.\u001b[39mserver\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mFedAvg(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m         fraction_fit\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m         fraction_evaluate\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m         \u001b[39m#evaluate_metrics_aggregation_fn=weighted_average,\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39m# Start simulation\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m fl\u001b[39m.\u001b[39msimulation\u001b[39m.\u001b[39mstart_simulation(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m     client_fn\u001b[39m=\u001b[39mclient_fn,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m     num_clients\u001b[39m=\u001b[39mNUM_OF_CLIENTS,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     config\u001b[39m=\u001b[39mfl\u001b[39m.\u001b[39mserver\u001b[39m.\u001b[39mServerConfig(num_rounds\u001b[39m=\u001b[39mNUM_OF_ROUNDS),\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     strategy\u001b[39m=\u001b[39mstrategy,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Jon\\anaconda3\\envs\\py310\\lib\\site-packages\\flwr\\simulation\\app.py:196\u001b[0m, in \u001b[0;36mstart_simulation\u001b[1;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[0;32m    193\u001b[0m     initialized_server\u001b[39m.\u001b[39mclient_manager()\u001b[39m.\u001b[39mregister(client\u001b[39m=\u001b[39mclient_proxy)\n\u001b[0;32m    195\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m hist \u001b[39m=\u001b[39m _fl(\n\u001b[0;32m    197\u001b[0m     server\u001b[39m=\u001b[39;49minitialized_server,\n\u001b[0;32m    198\u001b[0m     config\u001b[39m=\u001b[39;49minitialized_config,\n\u001b[0;32m    199\u001b[0m )\n\u001b[0;32m    201\u001b[0m event(EventType\u001b[39m.\u001b[39mSTART_SIMULATION_LEAVE)\n\u001b[0;32m    203\u001b[0m \u001b[39mreturn\u001b[39;00m hist\n",
      "File \u001b[1;32mc:\\Users\\Jon\\anaconda3\\envs\\py310\\lib\\site-packages\\flwr\\server\\app.py:201\u001b[0m, in \u001b[0;36m_fl\u001b[1;34m(server, config)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fl\u001b[39m(\n\u001b[0;32m    197\u001b[0m     server: Server,\n\u001b[0;32m    198\u001b[0m     config: ServerConfig,\n\u001b[0;32m    199\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m History:\n\u001b[0;32m    200\u001b[0m     \u001b[39m# Fit model\u001b[39;00m\n\u001b[1;32m--> 201\u001b[0m     hist \u001b[39m=\u001b[39m server\u001b[39m.\u001b[39;49mfit(num_rounds\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_rounds, timeout\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mround_timeout)\n\u001b[0;32m    202\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: losses_distributed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mlosses_distributed))\n\u001b[0;32m    203\u001b[0m     log(INFO, \u001b[39m\"\u001b[39m\u001b[39mapp_fit: metrics_distributed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(hist\u001b[39m.\u001b[39mmetrics_distributed))\n",
      "File \u001b[1;32mc:\\Users\\Jon\\anaconda3\\envs\\py310\\lib\\site-packages\\flwr\\server\\server.py:89\u001b[0m, in \u001b[0;36mServer.fit\u001b[1;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_initial_parameters(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m     88\u001b[0m log(INFO, \u001b[39m\"\u001b[39m\u001b[39mEvaluating initial parameters\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mevaluate(\u001b[39m0\u001b[39;49m, parameters\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters)\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     log(\n\u001b[0;32m     92\u001b[0m         INFO,\n\u001b[0;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minitial parameters (loss, other metrics): \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m         res[\u001b[39m0\u001b[39m],\n\u001b[0;32m     95\u001b[0m         res[\u001b[39m1\u001b[39m],\n\u001b[0;32m     96\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jon\\anaconda3\\envs\\py310\\lib\\site-packages\\flwr\\server\\strategy\\fedavg.py:163\u001b[0m, in \u001b[0;36mFedAvg.evaluate\u001b[1;34m(self, server_round, parameters)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    162\u001b[0m parameters_ndarrays \u001b[39m=\u001b[39m parameters_to_ndarrays(parameters)\n\u001b[1;32m--> 163\u001b[0m eval_res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_fn(server_round, parameters_ndarrays, {})\n\u001b[0;32m    164\u001b[0m \u001b[39mif\u001b[39;00m eval_res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Jon\\Documents\\VSCode Projects\\Edge-IIoT-FL\\04b-Multiclass Federated-Learning-with-Edge-IIoT.ipynb Cell 29\u001b[0m in \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39mglobal\u001b[39;00m eval_count\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# Update model with the latest parameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m server_model\u001b[39m.\u001b[39;49mset_weights(parameters)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mServer Evaluating...\u001b[39m\u001b[39m\"\u001b[39m, eval_count)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Jon/Documents/VSCode%20Projects/Edge-IIoT-FL/04b-Multiclass%20Federated-Learning-with-Edge-IIoT.ipynb#X41sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m server_model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Jon\\anaconda3\\envs\\py310\\lib\\site-packages\\keras\\engine\\base_layer.py:1784\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1781\u001b[0m         expected_num_weights \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[39mif\u001b[39;00m expected_num_weights \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(weights):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1785\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mYou called `set_weights(weights)` on layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1786\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith a weight list of length \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, but the layer was \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1787\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexpecting \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m weights. Provided weights: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1788\u001b[0m         \u001b[39m%\u001b[39m (\n\u001b[0;32m   1789\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[0;32m   1790\u001b[0m             \u001b[39mlen\u001b[39m(weights),\n\u001b[0;32m   1791\u001b[0m             expected_num_weights,\n\u001b[0;32m   1792\u001b[0m             \u001b[39mstr\u001b[39m(weights)[:\u001b[39m50\u001b[39m],\n\u001b[0;32m   1793\u001b[0m         )\n\u001b[0;32m   1794\u001b[0m     )\n\u001b[0;32m   1796\u001b[0m weight_index \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   1797\u001b[0m weight_value_tuples \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"sequential_7\" with a weight list of length 262, but the layer was expecting 6 weights. Provided weights: [array([[[[-0.08516684, -0.04290653, -0.05079073, ..."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from trans import *\n",
    "\n",
    "print('scikit-learn {}.'.format(sklearn.__version__))\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"tf\", tf.__version__)\n",
    "# Make TensorFlow log less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "class NumpyFlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, train_data, train_labels):\n",
    "        self.model = model\n",
    "        self.cid = cid\n",
    "        self.train_data = train_data\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Training...\")\n",
    "        self.model.fit(self.train_data, self.train_labels, epochs=1, batch_size=32)\n",
    "        print (\"Client \", self.cid, \"Training complete...\")\n",
    "        return self.model.get_weights(), len(self.train_data), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        print (\"Client \", self.cid, \"Evaluating...\")\n",
    "        loss, accuracy = self.model.evaluate(self.train_data, self.train_labels, batch_size=32)\n",
    "        print (\"Client \", self.cid, \"Evaluating complete...\", accuracy, loss)\n",
    "        return loss, len(self.train_data), {\"accuracy\": accuracy}\n",
    "    \n",
    "    def predict(self, incoming):\n",
    "        prediction = np.argmax( self.model.predict(incoming) ,axis=1)\n",
    "        return prediction\n",
    "\n",
    "def client_fn(cid: str) -> NumpyFlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    #model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)\n",
    "    #model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    print (\"Client ID:\", cid)\n",
    "\n",
    "    model = Sequential([\n",
    "      #Flatten(input_shape=(79,1)),\n",
    "      Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "      Dense(256, activation='sigmoid'),\n",
    "      Dense(128, activation='sigmoid'), \n",
    "      #Dense(18, activation='sigmoid'),  \n",
    "      Dense(len(label.unique()), activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "   \n",
    "    partition_id = int(cid)\n",
    "    X_train_c = fl_X_train[partition_id]\n",
    "    y_train_c = fl_y_train[partition_id]\n",
    "\n",
    "    # Create a  single Flower client representing a single organization\n",
    "    return NumpyFlowerClient(cid, model, X_train_c, y_train_c)\n",
    "\n",
    "\n",
    "print (\"Deploy simulation...\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "eval_count = 0\n",
    "\n",
    "def get_evaluate_fn(server_model):\n",
    "    global eval_count\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "    # The `evaluate` function will be called after every round\n",
    "    \n",
    "    \n",
    "    def evaluate(server_round, parameters, config):\n",
    "        global eval_count\n",
    "        \n",
    "        # Update model with the latest parameters\n",
    "        server_model.set_weights(parameters)\n",
    "        print (\"Server Evaluating...\", eval_count)\n",
    "        loss, accuracy = server_model.evaluate(X_test, y_test)\n",
    "        \n",
    "        y_pred = server_model.predict(X_test)\n",
    "        print (\"Prediction: \", y_pred, y_pred.shape)\n",
    "        #cmatrix = confusion_matrix(y_test, np.rint(y_pred))\n",
    "        #print (\"confusion_matrix:\", cmatrix, cmatrix.shape)\n",
    "                        \n",
    "        print (\"Server Evaluating complete...\", accuracy, loss)\n",
    "        \n",
    "        np.save(\"y_pred-\" + str(eval_count) + \".npy\", y_pred)\n",
    "        #np.save(\"cmatrix-\" + str(eval_count) + \".npy\", cmatrix)\n",
    "        eval_count = eval_count + 1\n",
    "        \n",
    "        return loss, {\"accuracy\": accuracy}\n",
    "    return evaluate\n",
    "\n",
    "\n",
    "\n",
    "server_model = Sequential([\n",
    "      #Flatten(input_shape=(79,1)),\n",
    "      Flatten(input_shape=(fl_X_train[0].shape[1] , 1)),\n",
    "      Dense(256, activation='sigmoid'),\n",
    "      Dense(128, activation='sigmoid'), \n",
    "      #Dense(18, activation='sigmoid'),  \n",
    "      Dense(len(label.unique()), activation='sigmoid')\n",
    "    ])\n",
    "server_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=2, #10,\n",
    "        min_evaluate_clients=2, #5,\n",
    "        min_available_clients=2, #10,\n",
    "        evaluate_fn=get_evaluate_fn(server_model),\n",
    "        #evaluate_metrics_aggregation_fn=weighted_average,\n",
    ")\n",
    "\n",
    "# Start simulation\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_OF_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_OF_ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
